### CUDA Learning Plan: Professional CUDA C Programming

Based on your selection of **"Professional CUDA C Programming"** and your Jetson Orin NX, here is a hands-on learning plan tailored for your 3-hour per week schedule. This plan focuses on getting you up and running with practical code as quickly as possible, aligning with your learning style.

---

| Week | Date Range | Chapters/Sections to Read | Weekly Goal | Learning Objectives | Hands-on Activities | Success Criteria |
| :--- | :--- | :--- | :--- | :--- | :--- | :--- |
| **1** | Aug 11 - Aug 17 | **Ch. 1:** Sec. 1.2, 1.4, 1.5. **Ch. 2:** Sec. 2.1. | Set up the Jetson environment and compile a basic CUDA program. | Understand the Jetson's architecture; install the CUDA Toolkit; compile and run your first program. | Install the CUDA Toolkit on the Jetson Orin NX; compile and run the "Hello, World!" example from the book. | The "Hello, World!" program executes successfully, showing host and device output. |
| **2** | Aug 18 - Aug 24 | **Ch. 2:** Sec. 2.2, 2.3, 2.4. **Ch. 3:** Sec. 3.1, 3.2. | Grasp the fundamental CUDA programming model with threads, blocks, and grids. | Understand the host/device model; learn kernel launch syntax; comprehend how threads are organized. | Implement a simple vector addition kernel and launch it from the host, experimenting with different grid/block sizes. | The vector addition program produces the correct result for a given input size. |
| **3** | Aug 25 - Aug 31 | **Ch. 4:** Sec. 4.1, 4.2, 4.3. | Master CUDA's memory model and data transfer between the host and device. | Understand global, shared, and local memory; learn to use `cudaMalloc`, `cudaMemcpy`, and `cudaFree`. | Implement a vector copy program, focusing on correct memory allocation and efficient data transfer. | The vector copy program correctly moves data from host to device and back, with no memory leaks. |
| **4** | Sep 1 - Sep 7 | **Review Week.** | Reinforce core concepts and solidify your understanding of the first three weeks. | Debugging skills for basic CUDA; reinforce kernel launch and memory transfer concepts. | Rerun your vector addition and copy programs; use `cuda-memcheck` to find any memory errors or race conditions. | Can troubleshoot simple CUDA errors; you have a clear mental model of data flow between CPU and GPU. |
| **5** | Sep 8 - Sep 14 | **Ch. 5:** Sec. 5.1, 5.2, 5.3. | Begin optimizing for performance by addressing memory issues. | Learn about memory coalescing and bank conflicts; understand the role of shared memory for optimization. | Modify a simple kernel to use shared memory to perform a reduction (e.g., sum an array). Measure the performance difference. | The shared memory version of your reduction kernel is measurably faster than the global memory version. |
| **6** | Sep 15 - Sep 21 | **Ch. 6:** Sec. 6.1, 6.2, 6.3. | Explore advanced memory features. | Understand texture and constant memory, and how they can be used for performance gains on the Jetson. | Implement a 2D image processing kernel (e.g., a simple blur) and experiment with using texture memory to speed up access. | The image processing kernel works correctly; you can describe the benefits of using texture memory for spatial data. |
| **7** | Sep 22 - Sep 28 | **Ch. 7:** Sec. 7.1, 7.2, 7.3. | Understand asynchronous operations with CUDA streams and events. | Learn about CUDA streams for concurrency; understand `cudaEvents` for synchronization; comprehend `pinned` memory. | Modify a previous program to use CUDA streams to overlap computation and data transfers. Time the execution. | Your program correctly uses streams; you can explain how overlapping tasks improves overall throughput. |
| **8** | Sep 29 - Oct 5 | **Review Week.** | Reinforce your understanding of optimization and asynchronous patterns. | Debugging skills for advanced CUDA; understanding of `pinned` memory and asynchronous tasks. | Review your optimized and asynchronous programs; document the performance gains you observed. | Solid knowledge of optimization techniques; can debug asynchronous CUDA code. |
| **9** | Oct 6 - Oct 12 | **Ch. 8:** Sec. 8.1, 8.2, 8.3. | Work with CUDA libraries for common tasks. | Understand the purpose of cuBLAS, cuFFT, and Thrust; learn how to use these libraries. | Implement a small program that uses cuBLAS for a matrix multiplication. | The program correctly uses cuBLAS to perform matrix multiplication, showcasing a professional library. |
| **10** | Oct 13 - Oct 19 | **Ch. 9:** Sec. 9.1, 9.2, 9.3. | Explore multi-GPU and heterogeneous computing. | Understand how to manage multiple GPUs and how a CPU and GPU can cooperate on a task. | As the Jetson has a single GPU, focus on the book's examples on heterogeneous computing and how CPU/GPU cooperation is managed. | You can explain how to manage tasks between the CPU and GPU on your Jetson Orin NX. |
| **11** | Oct 20 - Oct 26 | **Ch. 10:** Sec. 10.1, 10.2, 10.3. | Learn to debug and profile your CUDA code effectively. | Understand the debugging workflow; learn to use `nvprof` and NVIDIA Nsight to find bottlenecks. | Use NVIDIA Nsight to profile one of your most complex kernels. Analyze the output to identify and fix a performance bottleneck. | You can successfully profile a kernel and interpret the output to improve its performance. |
| **12** | Oct 27 - Nov 2 | **Review Week.** | Synthesize your knowledge of professional CUDA tools and practices. | Connect concepts of profiling, libraries, and heterogeneous computing. | Review your code and notes from the last three weeks, paying close attention to profiling and library usage. | You feel confident in using professional tools to write and optimize CUDA code. |
| **13** | Nov 3 - Nov 9 | **Ch. 11:** Sec. 11.1, 11.2, 11.3. | Interoperate CUDA with other APIs for graphics or compute. | Learn how to share data between CUDA and OpenGL/Vulkan, which is useful for robotics applications. | Implement a small program that uses OpenGL to render data processed by a CUDA kernel on your Jetson. | The program correctly uses CUDA to process data and OpenGL to display it. |
| **14** | Nov 10 - Nov 16 | **Ch. 12:** Sec. 12.1, 12.2. | Leverage modern C++ features in your CUDA code. | Understand how to use C++ templates and lambdas to write more flexible and maintainable CUDA kernels. | Rewrite one of your earlier kernels (e.g., vector addition) using a C++ template to make it work with different data types. | Your kernel is now more generic and reusable due to the use of C++ features. |
| **15** | Nov 17 - Nov 23 | **Final Project/Next Steps.** | Consolidate everything you've learned and plan for the future. | Solidify your mastery of CUDA fundamentals; understand how to continue applying CUDA in your projects. | Rerun and optimize your final project; write a blog post summarizing your journey; brainstorm next steps. | You feel confident in your ability to write, optimize, and debug CUDA code on your Jetson. |